{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e58c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "本文档说明：\n",
    "\n",
    "也会删除特征，放在数据导入部分，离散化后删除原来特征\n",
    "\n",
    "可视化决定如何进行离散化\n",
    "然后借助等距来分箱（除非时间不够，不然等距等频用处不大）\n",
    "信息熵等分箱更是像聚类一样杂，没有标准\n",
    "\n",
    "离散编码一般就是独热\n",
    "平均和WOE感觉更适合回归问题\n",
    "\n",
    "日期处理pass\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28bdf6f",
   "metadata": {},
   "source": [
    "#  数据导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81fd3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import dtale\n",
    "from sklearn import preprocessing as pp\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549e4021",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath=\"C:/Users/Huai/Desktop/tool/train_v3_discrete_temp.csv\"\n",
    "df=pd.read_csv(fpath)\n",
    "\n",
    "#简单数据查看、不必dtale\n",
    "df.shape\n",
    "df.head(5)\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd2ebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(df=df, figsize=(8, 4), fontsize=18) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884fb553",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtale.show(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79496cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#删除特征  #平均码可以减小一个维度\n",
    "#df=df.drop(['PassengerId',\"Name\"],axis=1)\n",
    "df=df.drop(['SibSp','Parch'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8074783",
   "metadata": {},
   "source": [
    "#  连续值离散化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f855ac",
   "metadata": {},
   "source": [
    "##  可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b1d0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1连续值离散化（可视化）\n",
    "import re\n",
    "def hist_line(x,y,target_class,bins_num,color):\n",
    "    #设置格式 \n",
    "    sns.set_style(\"whitegrid\")\n",
    "    #设置图形大小\n",
    "    plt.rcParams['figure.figsize'] = (18.0,8.0)\n",
    "    fig = plt.figure()\n",
    "    #画柱形图\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    n,bins_rule,patches=ax1.hist(x, bins=bins_num, facecolor=color, edgecolor=\"black\", alpha=0.5)\n",
    "    ax1.set_ylabel(x.name, fontsize='15')\n",
    "    ax1.set_title(x.name+\"-y\",fontsize='20')\n",
    "    \n",
    "    for i in range(len(bins_rule)):\n",
    "        bins_rule[i]=round(bins_rule[i],3)\n",
    "    plt.xticks(bins_rule,bins_rule, fontsize=15, rotation=45)#横坐标刻度，用rule设置\n",
    "\n",
    "    #print(bins_rule) #[18.  25.7 33.4 41.1 48.8 56.5 64.2 71.9 79.6 87.3 95. ]\n",
    "    height=[]\n",
    "    target=[]\n",
    "    target_name=y.name\n",
    "    for i in range((len(bins_rule)-1)):\n",
    "        height.append(   int(re.findall(r\"height=(.+?),\",str(patches[i]))[0])   )\n",
    "        #print(\"rule:\",bins_rule[i],bins_rule[i+1],\"height:\",height)  height=[[\"height1\"],[\"height2\"],[\"height3\"]]\n",
    "        new_ser=df.loc[ (x>=bins_rule[i]) & (x<bins_rule[i+1]), target_name]\n",
    "        target.append(  new_ser[new_ser==target_class].count() )\n",
    "        #target.append(df.loc[ (x>=bins_rule[i]) & (x<bins_rule[i+1]), target_name].sum())  #这个只能应用于目标为1/0  要修改！！！\n",
    "        #print(target) #[169, 830, 730, 392, 362, 280, 81, 86, 27, 3]\n",
    "    print(\"Height：\",height)\n",
    "    print(\"Target:\",target)\n",
    "    #画折线图 \n",
    "    ax2 = ax1.twinx()   #组合图必须加这个\n",
    "    line_x=[]\n",
    "    line_y=[]\n",
    "    for i in range((len(bins_rule)-1)):\n",
    "        line_x.append(   round((bins_rule[i]+bins_rule[i+1])/2,2)      )\n",
    "        line_y.append(   round((target[i]/(height[i]-target[i])),2)    ) \n",
    "    \n",
    "    #print(line_x)\n",
    "    print(\"y-1:0 :\",line_y)\n",
    "    ax2.plot(line_x, line_y, 'slateblue',ms=5, marker='o',linewidth=0.7)\n",
    "    ax2.set_ylabel('y-1:0',fontsize='15')\n",
    "    for a, b in zip(line_x, line_y):\n",
    "        plt.text(a, b+0.0, b, ha='center', va='bottom', fontsize=15)\n",
    "    ax2.grid(None)#不展示右轴的网格\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "x = df[\"number\"]\n",
    "y = df[\"Survived\"]\n",
    "target_class=1#y中的阳性样本，最后的比值是（阳性样本数量/其他）\n",
    "bins_num=[-1,0.5,3.5,50]#[18,25,30,60,95]#也可是一个数字\n",
    "color=\"khaki\"\n",
    "hist_line(x,y,target_class,bins_num,color)\n",
    "\"输出 Height Target Y-1:0\"\n",
    "#记得保存规则！！！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9babca",
   "metadata": {},
   "source": [
    "##  分箱"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b852fa0",
   "metadata": {},
   "source": [
    "###  等距分箱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3152aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"number\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a44701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser=df[\"number\"].copy()\n",
    "#class_bin对于等距 数字是分几个类别  list是把极值进行划分\n",
    "#class_bin=5\n",
    "class_bin=[-1,0.5,3.5,50]\n",
    "class_label=[\"number_s\",\"number_m\",\"number_l\"]\n",
    "\n",
    "new_ser,rule=pd.cut(ser,bins=class_bin,right=True,labels=class_label,retbins=True)\n",
    "print(new_ser)\n",
    "print(new_ser.value_counts())\n",
    "\n",
    "#记得保存规则！！！\n",
    "print(rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae600ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"number\"]=new_ser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a175693",
   "metadata": {},
   "source": [
    "###  等频分箱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40873fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser=df[\"Fare\"].copy()\n",
    "#class_bin对于等频 数字是分几个类别  list是把数量进行划分 前30% 50%类似 且范围[0-1]\n",
    "class_bin=5\n",
    "#class_bin=[0,0.25,0.5,0.75,0.8,1]\n",
    "class_label=[\"one\",\"two\",\"three\",\"four\",\"five\"]\n",
    "\n",
    "new_ser,rule=pd.qcut(ser,q=class_bin,labels=class_label,retbins=True,duplicates=\"drop\")\n",
    "print(new_ser)\n",
    "print(new_ser.value_counts())\n",
    "print(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10632cb",
   "metadata": {},
   "source": [
    "##  信息熵分箱"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9266228",
   "metadata": {},
   "source": [
    "###  信息熵分箱(详细代码方法：不方便使用)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bb24d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class entropy:\n",
    "    @staticmethod\n",
    "    def entropy(x):\n",
    "        p=x.value_counts(normalize=True)\n",
    "        p=p[p>0]\n",
    "        e=-(p*np.log2(p)).sum()\n",
    "        return e\n",
    "    @staticmethod\n",
    "    def cond_entropy(x,y):\n",
    "        p=y.value_counts(normalize=True)\n",
    "        e=0\n",
    "        for yi in y.unique():\n",
    "            e+=p[yi]*entropy.entropy(x[y==yi])\n",
    "        return 0\n",
    "    @staticmethod\n",
    "    def info_gain(x,y):\n",
    "        g=entropy.entropy(x)-entropy.cond_entropy(x,y)\n",
    "        return g\n",
    "\n",
    "def _is_too_small(df,min_count):\n",
    "    return df.shape[0]<min_count\n",
    "def _is_only_one_class(df,label):\n",
    "    return len(df[label].unique().tolist())==1\n",
    "\n",
    "\n",
    "\n",
    "def get_max_gain_point(df, label, feature_col):\n",
    "    '''\n",
    "    分箱后，使用离散方法计算信息增益\n",
    "    注意这里的for实现效率较低，实践中请先粗分类\n",
    "    '''\n",
    "    gain, max_p = -1, -1\n",
    "    ps = df[feature_col].unique().tolist()\n",
    "    ps.sort()\n",
    "\n",
    "    if len(ps) < 2:\n",
    "        return -1, None\n",
    "\n",
    "    for pp in ps:\n",
    "        #tmp = (df[feature_col] <= pp).astype(int)\n",
    "        tmp = (df[feature_col] < pp).astype(int)\n",
    "        g = entropy.info_gain(df[label], tmp)\n",
    "        if g > gain:\n",
    "            gain = g\n",
    "            max_p = pp\n",
    "    return gain, max_p\n",
    "\n",
    "def cut_by_entropy(df, label, loop=3, min_count=5, margin=0.01):\n",
    "    '''停止准则：\n",
    "    1、已到循环次数\n",
    "    2、信息增益增加小于阈值（用最小熵，不便定义熵值的大小）\n",
    "    '''\n",
    "    assert len(df.columns) == 2, 'not support'\n",
    "\n",
    "    def _get_best_points(df, label, feature_col, loop, min_count,  margin):\n",
    "        if loop == 0 or _is_only_one_class(df,label) or _is_too_small(df,min_count):\n",
    "            print(\"loop end\")\n",
    "            return [None]\n",
    "        else:\n",
    "            # 计算信息增益\n",
    "            gain, max_p = get_max_gain_point(df, label, feature_col)\n",
    "            print('max_p={},gain={}'.format(max_p, gain))\n",
    "            # 信息增益小于指定阈值时停止分箱\n",
    "            if gain < margin:\n",
    "                return [None]\n",
    "\n",
    "            # 左闭，右开\n",
    "            left = df.loc[df[feature_col] < max_p, :]\n",
    "            right = df.loc[df[feature_col] >= max_p, :]\n",
    "            \n",
    "            \n",
    "\n",
    "            # 递归分箱\n",
    "            return [max_p] + \\\n",
    "                _get_best_points(left, label, feature_col,loop - 1, min_count,  margin) + \\\n",
    "                _get_best_points(right, label, feature_col, loop - 1, min_count,  margin)\n",
    "\n",
    "    feature_col = [aa for aa in df.columns.tolist() if aa != label][0]\n",
    "    points = _get_best_points(df, label, feature_col, loop, min_count, margin)\n",
    "    points = [p for p in points if p is not None]\n",
    "    points = list(set(points))\n",
    "    points.sort()\n",
    "    return points\n",
    "\n",
    "cut_by_entropy(df[[\"Fare\",\"Survived\"]],\"Survived\", loop=2, min_count=1, margin=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4798bb",
   "metadata": {},
   "source": [
    "###  信息熵分箱(sklearn决策树方法)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad1da4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Fare\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d03e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# max_depth=3，表示进行3次划分构造3层的树结构\n",
    "def dt_entropy_cut(x, y, max_depth=3, criterion='entropy'):  \n",
    "    dt = DecisionTreeClassifier(criterion=criterion, max_depth=max_depth)\n",
    "    dt.fit(x.values.reshape(-1, 1), y)\n",
    "    qts = dt.tree_.threshold[np.where(dt.tree_.children_left > -1)]\n",
    "    if qts.shape[0] == 0:\n",
    "        qts = np.array([np.median(data[:, feature])])\n",
    "    else:\n",
    "        qts = np.sort(qts)\n",
    "    return qts\n",
    "\n",
    "cutoff = dt_entropy_cut(df[\"Fare\"], df[\"Survived\"], max_depth=3, criterion='entropy')#gini  #------------可以修改参数\n",
    "cutoff=cutoff.tolist()\n",
    "\n",
    "#在cutoff加上两边才是真正的rule！！！\n",
    "print(cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7539934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#方便审查决策树分辨结果\n",
    "ser=df[\"Fare\"].copy()\n",
    "class_bin=[-1000]+cutoff+[1000]#要给两边添加边界\n",
    "class_label=[\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\"]\n",
    "\n",
    "new_ser,rule=pd.cut(ser,bins=class_bin,right=True,labels=class_label,retbins=True)\n",
    "\n",
    "#查看分箱后的类别数量\n",
    "print(new_ser.value_counts())\n",
    "\"\"\"\n",
    "e    435\n",
    "d    153\n",
    "c    141\n",
    "h     89\n",
    "a     28\n",
    "f     15\n",
    "b     13\n",
    "g      5\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8239a6",
   "metadata": {},
   "source": [
    "##  卡方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628229e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac97364",
   "metadata": {},
   "source": [
    "##  Best-KS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9307fd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31db12cd",
   "metadata": {},
   "source": [
    "#  离散值编码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a6c765",
   "metadata": {},
   "source": [
    "## 定序；划分类（避免类别太多）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bb1f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ab0acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"SibSp\"])\n",
    "print(\"\\n\")\n",
    "print(df[\"SibSp\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb11482",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.1定序值\n",
    "ser=df[\"number\"].copy()\n",
    "#ser[ser==\"Fare_s\"]=\"a\"#-------------0\n",
    "#ser[ser==\"Fare_m\"]=\"b\"#-------------1\n",
    "#ser[ser==\"Fare_l\"]=\"c\"#-------------2\n",
    "name_list=[\"number_s\",\"number_m\",\"number_l\"]\n",
    "#按照字母序 a:0  b:1\n",
    "\n",
    "trans=pp.LabelEncoder().fit(np.array(name_list))\n",
    "new_ser=trans.transform(ser)\n",
    "#return trans, new_ser\n",
    "\n",
    "print(new_ser)\n",
    "\n",
    "df[\"number\"]=new_ser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33755e00",
   "metadata": {},
   "source": [
    "## 独热编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a951f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"Fare\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e766ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.2独热  #先定序后独热\n",
    "ser=df[\"number\"].copy()\n",
    "temp = np.array(ser)\n",
    "temp = temp.reshape(temp.shape[0], 1)\n",
    "trans1=pp.OneHotEncoder().fit(temp)\n",
    "trans2=trans1\n",
    "temp = trans1.transform(temp).toarray()  #woc 后面加一个.toarray()就跑通了 https://blog.csdn.net/small__roc/article/details/122947001\n",
    "new_df = pd.DataFrame(temp)\n",
    "print(new_df)#这里列名0-1-2 和定序值中的0-1-2对应"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad450a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Number_l\",\"Number_m\",\"Number_s\"]]=new_df[[0,1,2]]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ec2c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#删除特征\n",
    "#df=df.drop(['PassengerId',\"Name\"],axis=1)\n",
    "df=df.drop(['number'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce70f4dc",
   "metadata": {},
   "source": [
    "## 平均编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55d00a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"Embarked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b58c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.3平均码\n",
    "#http://helios.mm.di.uoa.gr/~rouvas/ssi/sigkdd/sigkdd.vol3.1/barreca.pdf\n",
    "feature=\"Embarked\"\n",
    "target=\"Survived\"\n",
    "k=400 #n=400 认为先验后验一样重要  #z=(n-k)/f\n",
    "f=500   #坡度平缓 越大越缓慢\n",
    "\n",
    "#获得先验\n",
    "name_list=[feature,target]\n",
    "mean_df = pd.DataFrame(columns=[\"feature\", \"target\"])\n",
    "mean_df[[\"feature\",\"target\"]]=df[name_list].copy()\n",
    "#获得总行数/样本数\n",
    "row_len=mean_df.shape[0]  \n",
    "#获得先验概率\n",
    "prior_df=mean_df[\"target\"].value_counts(ascending=True).sort_index(ascending=True)/row_len#(ascending=True).sort_index(ascending=True)字母序\n",
    "#0    0.620023\n",
    "#1    0.379977\n",
    "prior_index=(prior_df.index).tolist()\n",
    "prior_list=prior_df.tolist()\n",
    "#[0, 1]\n",
    "#[0.6200227531285551, 0.3799772468714448]\n",
    "\n",
    "#获得后验\n",
    "feature_group = mean_df.groupby(\"feature\")\n",
    "#建立空字典\n",
    "d={}\n",
    "for key,value in feature_group:\n",
    "    # key  是feature的类别\n",
    "    # value就是相应的dataframe\n",
    "    temp_row_len=value.shape[0]\n",
    "    temp_posterior_df=value[\"target\"].value_counts(ascending=True).sort_index(ascending=True)/temp_row_len\n",
    "    #temp_posterior_index=(temp_posterior_df.index).tolist()  #不需要，因为和先验一致\n",
    "    temp_posterior_list=temp_posterior_df.tolist()\n",
    "    \n",
    "    #获得λ\n",
    "    n=temp_row_len\n",
    "    z=(n-k)/f\n",
    "    lambda_n=(  1/(1+np.exp(z))  )\n",
    "    final_list=np.array([x*lambda_n for x in prior_list]) +  np.array([x*(1-lambda_n) for x in temp_posterior_list])\n",
    "    \n",
    "    print(value)\n",
    "    print(\"\\n\")\n",
    "    print(\"n:\",temp_row_len)\n",
    "    print(\"Z:\",z)\n",
    "    print(\"λ:\",lambda_n)\n",
    "    print(\"prior:\",prior_list)\n",
    "    print(\"posterior:\",temp_posterior_list)\n",
    "    print(\"final:\",final_list)\n",
    "    print(\"\\n\")\n",
    "    print(\"----------------------------------\")\n",
    "    \n",
    "    #装入字典\n",
    "    d[key]=final_list\n",
    "print(d)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1fbd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#获得平均码之后的特征名\n",
    "mean_name_list=[]\n",
    "for i in prior_index:\n",
    "    mean_name_list=mean_name_list+[\"mean\"+\"_\"+feature+\"_\"+str(i)]\n",
    "\n",
    "#建立空df\n",
    "new_df = pd.DataFrame(columns=mean_name_list)\n",
    "\n",
    "#给new_df赋值\n",
    "flag=0\n",
    "for i in prior_index:\n",
    "    new_df[\"mean\"+\"_\"+feature+\"_\"+str(i)]=mean_df['feature'].apply(lambda x : d[x][flag])\n",
    "    flag=flag+1\n",
    "\n",
    "#展示和赋值\n",
    "#print(new_df)\n",
    "#df[mean_name_list]=new_df[mean_name_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143f1896",
   "metadata": {},
   "outputs": [],
   "source": [
    "#删除特征  #平均码可以减小一个维度\n",
    "#df=df.drop(['PassengerId',\"Name\"],axis=1)\n",
    "df=df.drop(['Sex','Pclass',\"Embarked\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5830343d",
   "metadata": {},
   "source": [
    "### 平均编码(cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deb9144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.3平均码\n",
    "#http://helios.mm.di.uoa.gr/~rouvas/ssi/sigkdd/sigkdd.vol3.1/barreca.pdf\n",
    "feature=\"Embarked\"\n",
    "target=\"Survived\"\n",
    "k=400 #n=400 认为先验后验一样重要\n",
    "f=500   #坡度平缓 越大越缓慢\n",
    "\n",
    "#获得先验\n",
    "name_list=[feature,target]\n",
    "mean_df = pd.DataFrame(columns=[\"feature\", \"target\"])\n",
    "mean_df[[\"feature\",\"target\"]]=df[name_list].copy()\n",
    "\n",
    "temp_cross=pd.crosstab(mean_df[\"feature\"],mean_df[\"target\"])\n",
    "cross=temp_cross.div(temp_cross.sum(axis=1),axis=0)\n",
    "print(temp_cross)\n",
    "print(cross)\n",
    "\n",
    "#也许会更好"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f403e05",
   "metadata": {},
   "source": [
    "## WOE编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3779e3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"Embarked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae93a7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WOE\n",
    "#现在对WOE码理解还不深，该处只适用于二分类\n",
    "feature=\"Embarked\"\n",
    "target=\"Survived\"\n",
    "\n",
    "#获得先验\n",
    "name_list=[feature,target]\n",
    "woe_df = pd.DataFrame(columns=[\"feature\", \"target\"])\n",
    "woe_df[[\"feature\",\"target\"]]=df[name_list].copy()\n",
    "#获得下分布\n",
    "prior_df=woe_df[\"target\"].value_counts(ascending=True).sort_index(ascending=True)#(ascending=True).sort_index(ascending=True)字母序\n",
    "#0    545\n",
    "#1    334\n",
    "prior_num_list=prior_df.tolist()\n",
    "#[545, 334]\n",
    "prior_num_rate=prior_num_list[0]/prior_num_list[1]\n",
    "\n",
    "\n",
    "#h获得后验\n",
    "feature_group = mean_df.groupby(\"feature\")\n",
    "#建立空字典\n",
    "d={}\n",
    "for key,value in feature_group:\n",
    "    # key  是feature的类别\n",
    "    # value就是相应的dataframe\n",
    "    temp_posterior_df=value[\"target\"].value_counts(ascending=True).sort_index(ascending=True)\n",
    "    temp_posterior_list=temp_posterior_df.tolist()\n",
    "    temp_posterior_num_rate=temp_posterior_list[0]/temp_posterior_list[1]\n",
    "    \n",
    "    \n",
    "    print(value)\n",
    "    print(\"\\n\")\n",
    "    print(temp_posterior_df)\n",
    "    print(temp_posterior_list)\n",
    "    print(temp_posterior_num_rate)\n",
    "    print(\"\\n\")\n",
    "    print(\"----------------------------------\")\n",
    "    \n",
    "    #装入字典\n",
    "    d[key]=np.log(temp_posterior_num_rate/prior_num_rate)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cd2733",
   "metadata": {},
   "outputs": [],
   "source": [
    "#获得WOE之后的特征名\n",
    "#建立空df\n",
    "new_df = pd.DataFrame(columns=[\"woe\"+\"_\"+feature])\n",
    "\n",
    "#给new_df赋值\n",
    "new_df[\"woe\"+\"_\"+feature]=woe_df['feature'].apply(lambda x : d[x])\n",
    "\n",
    "#展示和赋值\n",
    "print(new_df)\n",
    "#df[mean_name_list]=new_df[mean_name_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8369bfca",
   "metadata": {},
   "source": [
    "# 日期处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7812b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.处理日期  #这里关键是可以对日期的字符串进行拆分\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da2d6a8",
   "metadata": {},
   "source": [
    "# 数据导出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1082fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath_out=\"C:/Users/Huai/Desktop/tool/train_v3_discrete.csv\"\n",
    "df.to_csv(fpath_out,encoding='utf-8',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "299px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
