{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89240aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "本文档说明：\n",
    "\n",
    "特征生成由个各个阶段的表共同生成\n",
    "特征选择先过滤法排除，推荐双指标（先看和目标关系，再看特征之间关系）\n",
    "\n",
    "然后重采样\n",
    "\n",
    "最后包裹法 在deal_data_5\n",
    "\n",
    "还是先包裹后采样？  还是应该先采样，用包裹来降低噪声，先包裹再采样平白加了噪声。\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430280a0",
   "metadata": {},
   "source": [
    "# 数据导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b719ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import dtale\n",
    "from sklearn import preprocessing as pp\n",
    "import sklearn\n",
    "import imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133aceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据导入\n",
    "fpath=\"C:/Users/Huai/Desktop/tool/train.csv\"\n",
    "df=pd.read_csv(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dc525f",
   "metadata": {},
   "source": [
    "# 相关性的分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29099cc",
   "metadata": {},
   "source": [
    "## 相关性(pearson、kendall、spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c8d921",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "这一部分应该包括相关性和关联性（前者指线性相关）\n",
    "但是种类繁多，且最后应用是获得量化的衡量指标，供过滤法的特征选择使用\n",
    "可持续填充\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a7ff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#连续用Pearson\n",
    "#定序定距离 用Kendall   Spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee016015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.3热力图（相关性：仅连续值）\n",
    "%matplotlib inline\n",
    "f=df[[\"Age\",\"SibSp\",\"Pclass\"]].corr(method=\"pearson\")\n",
    "sns.heatmap(f,annot=True, cmap=\"Blues\") #cmap类似palette  annot是标注数字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e426cb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.3热力图（相关性：仅连续值）\n",
    "%matplotlib inline\n",
    "f=df[[\"Age\",\"Fare\",\"SibSp\",\"Pclass\"]].corr(method=\"kendall\")\n",
    "sns.heatmap(f,annot=True, cmap=\"Blues\") #cmap类似palette  annot是标注数字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5f4856",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.3热力图（相关性：仅连续值）\n",
    "%matplotlib inline\n",
    "f=df[[\"Age\",\"Fare\",\"SibSp\",\"Pclass\"]].corr(method=\"spearman\")\n",
    "sns.heatmap(f,annot=True, cmap=\"Blues\") #cmap类似palette  annot是标注数字"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8d9f1d",
   "metadata": {},
   "source": [
    "## 卡方检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82137d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#卡方独立性检验，热图展现p值，小于0.5确定为相关\n",
    "from scipy.stats import chi2_contingency\n",
    "%matplotlib inline\n",
    "\n",
    "f=df[[\"SibSp\",\"Parch\",\"Pclass\"]]\n",
    "\n",
    "features=f.columns\n",
    "len_f=len(features)\n",
    "chi_square_df1=pd.DataFrame(index=features,columns=features)#看p值\n",
    "chi_square_df2=pd.DataFrame(index=features,columns=features)#看是否相关\n",
    "for i in features:\n",
    "    for j in features:\n",
    "        temp_obs=pd.crosstab(df[i],df[j])\n",
    "        temp_p_value=chi2_contingency(temp_obs)\n",
    "        chi_square_df1[i][j]=temp_p_value[1]\n",
    "        chi_square_df2[i][j]=True if(temp_p_value[1]<0.05) else False #最后赋值是1-p 这样数值大就相关，大于0.95必然相关-------这里改置信\n",
    "for i in features:\n",
    "    chi_square_df1[i] = chi_square_df1[i].astype(float)#这样才能画图\n",
    "    chi_square_df2[i] = chi_square_df2[i].astype(float)#这样才能画图\n",
    "\n",
    "# 1---看p值\n",
    "#sns.heatmap(chi_square_df1,annot=True, cmap=\"Blues\") \n",
    "# 2---看相关\n",
    "sns.heatmap(chi_square_df2,annot=True, cmap=\"Blues\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec8bb89",
   "metadata": {},
   "source": [
    "# 生成新特征"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc89bf3",
   "metadata": {},
   "source": [
    "## 生成转换基元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8858226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#、主要使用featuretools来生成特征\n",
    "#https://www.jianshu.com/p/71782dbe2e1e\n",
    "import featuretools as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d2e403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成自己的基元\n",
    "#=ft.primitives.make_trans_primitive(function=new_way , input_types=[Numeric] , return_type=Numeric) #淦，官文说这个方法remove掉了\n",
    "#quick search -> create custom primitives -> Defining Custom Primitives\n",
    "from featuretools.primitives import AggregationPrimitive, TransformPrimitive\n",
    "from featuretools.tests.testing_utils import make_ecommerce_entityset\n",
    "from woodwork.column_schema import ColumnSchema\n",
    "from woodwork.logical_types import Datetime, NaturalLanguage\n",
    "\n",
    "class Square(TransformPrimitive):#------------------------------------------------\n",
    "    name = 'square'#--------------------------------------------------------------\n",
    "    input_types = [ColumnSchema(semantic_tags={'numeric'})]\n",
    "    return_type = ColumnSchema(semantic_tags={'numeric'})\n",
    "\n",
    "    def get_function(self):\n",
    "        def square(column):#-----------------------------------------------------\n",
    "            return column*column#-------------------------------------------------\n",
    "\n",
    "        return square#-------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cc62a0",
   "metadata": {},
   "source": [
    "## ft生成特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecc641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import featuretools as ft\n",
    "#https://featuretools.alteryx.com/en/stable/getting_started/getting_started_index.html  官方文档说的比较明白\n",
    "\n",
    "#新建一个实体集  新建一个表集\n",
    "es = ft.EntitySet(id = \"save\")\n",
    "\n",
    "#为实体集加入实体   为表集加入表\n",
    "#dataframe_name 当前表名称   #index当前表使用的索引\n",
    "es = es.add_dataframe( dataframe_name=\"titanic\",  dataframe=df,  index=\"PassengerId\")\n",
    "\n",
    "#这里简单使用了 + - * % 来生成特征  ['AddNumeric','SubtractNumeric','DivideNumeric', 'MultiplyNumeric']\n",
    "#agg_primitives=[\"mean\", \"sum\", \"mode\"] 这个应该只是在多表中起作用，设置[]不影响单表生成特征数\n",
    "#而且在官方文档中可以去找trans_primitives  加入到参数中  #[\"And\",\"Or\",\"SquareRoot\"]\n",
    "\n",
    "#使用自己的函数，不用字符串 [Square]\n",
    "feature_matrix, feature_defs = ft.dfs(entityset=es, \n",
    "                                      target_dataframe_name=\"titanic\",\n",
    "                                      agg_primitives=[],\n",
    "                                      trans_primitives=[Square,'AddNumeric','SubtractNumeric','DivideNumeric', 'MultiplyNumeric'],\n",
    "                                      max_depth=2)\n",
    "\n",
    "feature_matrix.head()\n",
    "#feature_defs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf97bffb",
   "metadata": {},
   "source": [
    "# 特征选择"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bb19fd",
   "metadata": {},
   "source": [
    "## 过滤法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c9bc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://doc.codingdict.com/sklearn/14/\n",
    "#好吧，冰书也抄了文档（汗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fed3fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf=df[[\"PassengerId\",\"Survived\",\"Pclass\",\"Fare\"]]\n",
    "ddf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d6e524",
   "metadata": {},
   "source": [
    "### 方差过滤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74db394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "#小于阈值的列会被删除\n",
    "threshold=100\n",
    "\n",
    "#设置过滤器\n",
    "sel = VarianceThreshold(threshold=threshold)\n",
    "\n",
    "temp_df=ddf.copy()#------------------这里应该要改成纯数值，不能有字符串\n",
    "new_df=pd.DataFrame()\n",
    "\n",
    "for i in temp_df.columns.tolist():\n",
    "    try: \n",
    "        temp_new_df=sel.fit_transform(temp_df[[i]].copy())#但是输出是array，那就只能自己写循环了\n",
    "    except:\n",
    "        print(i+\"不通过\")\n",
    "        continue#不然会把前面通过的特征值，赋给该特征\n",
    "    new_df[i]=pd.DataFrame(temp_new_df,columns=[i])\n",
    "\n",
    "new_df #这个时候new_df就带着特征名了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e7e0db",
   "metadata": {},
   "source": [
    "### 单指标过滤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b5c56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38896e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.1.2.1  保留前几名\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression#回归\n",
    "from sklearn.feature_selection import mutual_info_regression#回归\n",
    "from sklearn.feature_selection import chi2#分类\n",
    "from sklearn.feature_selection import f_classif#分类\n",
    "from sklearn.feature_selection import mutual_info_classif#分类\n",
    "#分类  回归  不要混着用！\n",
    "\n",
    "method=chi2\n",
    "k=2#选取前2名特征\n",
    "temp_df=ddf\n",
    "target=[\"Survived\"]\n",
    "features=[\"PassengerId\",\"Pclass\",\"Fare\"]\n",
    "\n",
    "selector = SelectKBest(method, k=k).fit(temp_df[features], temp_df[target])\n",
    "scores = selector.scores_#分值越大越好\n",
    "#输出评价分数\n",
    "#print(scores)\n",
    "\n",
    "#输出索引\n",
    "k_index=np.argsort(  np.array(scores)  )[(0-k):][::-1]\n",
    "#print(k_index)\n",
    "\n",
    "\n",
    "feature_list=temp_df[features].columns.tolist()\n",
    "new_df=pd.DataFrame()\n",
    "for i in k_index:\n",
    "    name=[feature_list[i]]\n",
    "    new_df[name]=temp_df[name]\n",
    "\n",
    "#左侧特征分数最高\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bb1439",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.1.2.2 保留前百分比\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import f_regression#回归\n",
    "from sklearn.feature_selection import mutual_info_regression#回归\n",
    "from sklearn.feature_selection import chi2#分类\n",
    "from sklearn.feature_selection import f_classif#分类\n",
    "from sklearn.feature_selection import mutual_info_classif#分类\n",
    "#分类  回归  不要混着用！\n",
    "\n",
    "\n",
    "method=chi2\n",
    "percentile=50#选取前30%的特征\n",
    "temp_df=ddf\n",
    "target=[\"Survived\"]\n",
    "features=[\"PassengerId\",\"Pclass\",\"Fare\"]\n",
    "\n",
    "selector = SelectPercentile(method, percentile=percentile).fit(temp_df[features], temp_df[target])\n",
    "scores = selector.scores_#分值越大越好\n",
    "#输出评价分数\n",
    "#print(scores)\n",
    "\n",
    "#输出索引\n",
    "#num是最终输出的特征数量\n",
    "import math\n",
    "num=math.floor(temp_df[features].shape[1]*percentile/100)+1#+1避免num=0，num=0不会进行筛选\n",
    "print(\"一共有特征数：\",temp_df[features].shape[1])\n",
    "print(\"取百分之：\",percentile)\n",
    "print(\"即要取特征数：\",temp_df[features].shape[1]*percentile/100)\n",
    "print(\"最终取特征数：\",num)\n",
    "k_index=np.argsort(  np.array(scores)  )[(0-num):][::-1]\n",
    "#print(k_index)\n",
    "\n",
    "\n",
    "feature_list=temp_df[features].columns.tolist()\n",
    "new_df=pd.DataFrame()\n",
    "for i in k_index:\n",
    "    name=[feature_list[i]]\n",
    "    new_df[name]=temp_df[name]\n",
    "\n",
    "#左侧特征分数最高\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792b17c1",
   "metadata": {},
   "source": [
    "### 双指标过滤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e705ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#冰书方法1  是先算IV排序然后根据相关性内部删除\n",
    "#一个是sklearn没有直接计算IV（IV意义不明，代码不能简便实现，而且只适用于二分类）\n",
    "#冰书方法2\n",
    "#同上，也是先排序再内部排除，但是讲述篇幅少，感觉也不是很常用，不太有自己实现的必要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609f0b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45085297",
   "metadata": {},
   "outputs": [],
   "source": [
    "#所以双指标过滤本质是先排序过滤（与目标联系），再内部过滤（内部联系）\n",
    "#所以这里只写如何进行内部过滤\n",
    "#即先找到内部强相关，然后保留其中和目标相关性更强的变量\n",
    "\n",
    "#一般而言上一步应该得到的是不带target的特征，所以target要单独列出来\n",
    "temp_df_target=ddf[[\"Survived\"]].copy()\n",
    "temp_df=ddf[[\"PassengerId\",\"Fare\",\"Pclass\"]].copy()\n",
    "threshold=0.5\n",
    "method=\"pearson\"\n",
    "\n",
    "\n",
    "fcorr=temp_df.corr(method=method)\n",
    "in_features=temp_df.columns.tolist()\n",
    "out_features=[]\n",
    "new_df=temp_df.copy()\n",
    "\n",
    "#print(in_features) #输入特征个数\n",
    "#print(fcorr)  #特征间相关性表\n",
    "\n",
    "for i in range(len(in_features)):\n",
    "    for j in range(len(in_features)):\n",
    "        if(i>=j):\n",
    "            continue\n",
    "        if(abs(fcorr.iloc[i,j])>=threshold):#>=threshold\n",
    "            i_name=in_features[i]\n",
    "            i_df=temp_df[[i_name]]\n",
    "            j_name=in_features[j]\n",
    "            j_df=temp_df[[j_name]]\n",
    "            tij_df=temp_df_target.copy()\n",
    "            tij_df[\"i\"]=i_df\n",
    "            tij_df[\"j\"]=j_df\n",
    "            tij_corr=tij_df.corr(method=method)\n",
    "            #print(tij_corr) #决定删除时相关性表  target与i 与j\n",
    "            i_score = abs(tij_corr.iloc[0,1])\n",
    "            j_score = abs(tij_corr.iloc[0,2])\n",
    "            if(i_score>=j_score):\n",
    "                out_features+=[j_name]#也可以多记录信息，如比较两个特征名 评分等\n",
    "                #因为可能多次删除同一特征，所以在最后统一删除\n",
    "                #new_df=new_df.drop(labels=j_name,axis=1)\n",
    "            else:\n",
    "                out_features+=[i_name]\n",
    "                #因为可能多次删除同一特征，所以在最后统一删除\n",
    "                #new_df=new_df.drop(labels=i_name,axis=1)\n",
    "\n",
    "#特征列表  去除重复被删除的特征\n",
    "out_features=list(set(out_features))\n",
    "\n",
    "#df中删除特征\n",
    "new_df=temp_df.drop(labels=out_features,axis=1)\n",
    "\n",
    "\n",
    "print(\"删除特征数:\",len(out_features))\n",
    "print(out_features)\n",
    "print(\"剩余特征数:\",len(in_features)-len(out_features))\n",
    "print(new_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028a3b99",
   "metadata": {},
   "source": [
    "## 包裹法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f02333",
   "metadata": {},
   "outputs": [],
   "source": [
    "#学会RFECV即可\n",
    "\"\"\"\n",
    "如果网格调参和RFECV应该是一个怎样的关系？\n",
    "如果两者不能合并，那必然需要一个先后，而RFECV不能先，因为模型参数没有信服力\n",
    "所以只能现网格调参获得一个差不多的参数，然后筛选特征  得到新特征再网格\n",
    "这一次再网格后还需要RFECV么？\n",
    "RFECV只少不多，多以如果目标是50，那第一次筛选到100然后网格，然后RFECV再筛选到50\n",
    "这样的话成为一个迭代的过程，显然次数越多越好，但到后期肯定上升有限\n",
    "所以我建议两轮应该就可以了，尤其是还不能确定该方法是否是业界使用的方法\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "既然不好加入到.py文件中（改结构是小事，关键是里面不是pd而是numpy连列名都没有不好操作）\n",
    "不如就用jupyter写\n",
    "可以为其另起一个文件\n",
    "\"\"\"\n",
    "#https://www.cnblogs.com/nxf-rabbit75/p/11122415.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b4eebc",
   "metadata": {},
   "source": [
    "## 嵌入法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95d11ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "嵌入法是在得到模型后\n",
    "根据特征对模型的解释来选择特征再训练\n",
    "所以我倾向其做了更多模型解释的内容\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfa2a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#见deal_data_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3490751d",
   "metadata": {},
   "source": [
    "# 模型展示与解释"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d20b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#这部分可能多杂，但是不会算难\n",
    "#在做项目的时候现找就可以，可以暂时不写\n",
    "#倒不如在这里把能解释的模型都解释一遍\n",
    "#可问题是不应该在jupyter notebook里写，因为py的模型在notebook里又展示不出来\n",
    "#见deal_data_6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025dbb04",
   "metadata": {},
   "source": [
    "# 数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab583773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主要是使用imblearn库\n",
    "# 下面链接做了一个基本讲解\n",
    "#https://blog.csdn.net/qq_39478403/article/details/115533295\n",
    "#我只需要 随机过采样 SMOTE（线性合成） ADASYN（线性合成，更关注离群点） 随机欠采样 （实际应用中欠采样使用较少）\n",
    "# https://github.com/heucoder/machinelearning#11 star star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1734cded",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf[[\"Survived\"]].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826adf2f",
   "metadata": {},
   "source": [
    "## 随机过采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8979146d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "\n",
    "y_df=ddf[[\"Survived\"]].copy()\n",
    "X_df=ddf[[\"PassengerId\",\"Fare\",\"Pclass\"]].copy()\n",
    "y_features=y_df.columns.tolist()\n",
    "X_features=X_df.columns.tolist()\n",
    "\n",
    "X_resampled, y_resampled = ros.fit_resample(X_df, y_df)\n",
    "\n",
    "# 将数据转换为数据框并命名列名\n",
    "X_resampled = pd.DataFrame(X_resampled, columns=X_features) \n",
    "y_resampled = pd.DataFrame(y_resampled, columns=y_features)\n",
    "new_resampled = pd.concat([X_resampled,y_resampled],axis=1)\n",
    "\n",
    "#返回的采样好的样本\n",
    "new_resampled\n",
    "\n",
    "#可以检查采样后的类别数量\n",
    "#new_resampled[y_features].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6e261b",
   "metadata": {},
   "source": [
    "## SMOTE过采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e01144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "ros = SMOTE()\n",
    "\n",
    "y_df=ddf[[\"Survived\"]].copy()\n",
    "X_df=ddf[[\"PassengerId\",\"Fare\",\"Pclass\"]].copy()\n",
    "y_features=y_df.columns.tolist()\n",
    "X_features=X_df.columns.tolist()\n",
    "\n",
    "X_resampled, y_resampled = ros.fit_resample(X_df, y_df)\n",
    "\n",
    "# 将数据转换为数据框并命名列名\n",
    "X_resampled = pd.DataFrame(X_resampled, columns=X_features) \n",
    "y_resampled = pd.DataFrame(y_resampled, columns=y_features)\n",
    "new_resampled = pd.concat([X_resampled,y_resampled],axis=1)\n",
    "\n",
    "#返回的采样好的样本\n",
    "new_resampled\n",
    "\n",
    "#可以检查采样后的类别数量\n",
    "#new_resampled[y_features].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48963071",
   "metadata": {},
   "source": [
    "## ADASYN过采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5172dfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "ros = ADASYN()\n",
    "\n",
    "y_df=ddf[[\"Survived\"]].copy()\n",
    "X_df=ddf[[\"PassengerId\",\"Fare\",\"Pclass\"]].copy()\n",
    "y_features=y_df.columns.tolist()\n",
    "X_features=X_df.columns.tolist()\n",
    "\n",
    "X_resampled, y_resampled = ros.fit_resample(X_df, y_df)\n",
    "\n",
    "# 将数据转换为数据框并命名列名\n",
    "X_resampled = pd.DataFrame(X_resampled, columns=X_features) \n",
    "y_resampled = pd.DataFrame(y_resampled, columns=y_features)\n",
    "new_resampled = pd.concat([X_resampled,y_resampled],axis=1)\n",
    "\n",
    "#返回的采样好的样本\n",
    "new_resampled\n",
    "\n",
    "#可以检查采样后的类别数量\n",
    "#new_resampled[y_features].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c8c310",
   "metadata": {},
   "source": [
    "## 随机欠采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f410a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "ros = RandomUnderSampler() \n",
    "\n",
    "y_df=ddf[[\"Survived\"]].copy()\n",
    "X_df=ddf[[\"PassengerId\",\"Fare\",\"Pclass\"]].copy()\n",
    "y_features=y_df.columns.tolist()\n",
    "X_features=X_df.columns.tolist()\n",
    "\n",
    "X_resampled, y_resampled = ros.fit_resample(X_df, y_df)\n",
    "\n",
    "# 将数据转换为数据框并命名列名\n",
    "X_resampled = pd.DataFrame(X_resampled, columns=X_features) \n",
    "y_resampled = pd.DataFrame(y_resampled, columns=y_features)\n",
    "new_resampled = pd.concat([X_resampled,y_resampled],axis=1)\n",
    "\n",
    "#返回的采样好的样本\n",
    "new_resampled\n",
    "\n",
    "#可以检查采样后的类别数量,降采样哦\n",
    "#new_resampled[y_features].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566df2a6",
   "metadata": {},
   "source": [
    "# 数据导出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c4cada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据输出\n",
    "fpath_out=\"C:/Users/Huai/Desktop/tool/train_v4_final.csv\"\n",
    "df.to_csv(fpath_out,encoding='utf-8',index=False)#不然左边会多一列"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
